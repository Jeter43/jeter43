# quant_system/domain/strategies/selection_technical.py
"""
å…¼å®¹ comp_trategy_HK_v5.4_20251017.py è¡Œä¸ºçš„æŠ€æœ¯é€‰è‚¡ç­–ç•¥å®ç°

è¯´æ˜ï¼š
- åŠ›æ±‚åœ¨ç­›é€‰é€»è¾‘ã€é˜ˆå€¼å’Œè¾“å‡ºé£æ ¼ä¸Šä¸æ—§è„šæœ¬ä¸€è‡´ï¼ˆæ”¾é‡ 1.5ã€å‡çº¿èšæ‹¢é˜ˆå€¼ 3%ã€å…è®¸åˆ†æ•° > 100 ç­‰ï¼‰
- ä½¿ç”¨ TechnicalAnalyzer å’Œ MultiDimensionScorer ä½œä¸ºæŒ‡æ ‡ä¸è¯„åˆ†å¼•æ“
- å¹¶å‘æ‹‰å†å²ä»¥æé«˜æ€§èƒ½
- è¯¦ç»† debug æ—¥å¿—è¾“å‡ºä»¥ä¾¿é€æ¡å¯¹æ¯”
- æ–°å¢ï¼šè¯¦ç»†çš„å…¥é€‰ç†ç”±è¯´æ˜
"""

import sys
import os
import logging
import random
import traceback
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import numpy as np

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•å¯å¯¼å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from quant_system.utils.logger import get_logger
from .base import SelectionStrategy, StrategyConfig, ExecutionResult
from quant_system.domain.analysis.technical_analyzer import TechnicalAnalyzer
from quant_system.domain.analysis.multi_dimension_scorer import MultiDimensionScorer

# é»˜è®¤å¸¸é‡ï¼ˆæ¥è¿‘æ—§è„šæœ¬è¡Œä¸ºï¼‰
DEFAULT_HISTORY_BARS = 120  # ä¼˜åŒ–ï¼šä»240å‡å°‘åˆ°120ï¼Œå‡å°‘50%æ•°æ®é‡
DEFAULT_BATCH_SIZE = 500
DEFAULT_MAX_ANALYSIS = 5000
DEFAULT_HISTORY_WORKERS = 8  # ä¼˜åŒ–ï¼šä»12é™åˆ°8ï¼Œæ›´ä¸¥æ ¼éµå®ˆAPIé¢‘ç‡é™åˆ¶ï¼ˆæ¯30ç§’60æ¬¡ï¼Œ8ä¸ªå¹¶å‘æ›´å®‰å…¨ï¼‰


class DataCache:
    """æ•°æ®ç¼“å­˜ç±» - ç”¨äºç¼“å­˜Kçº¿å’Œå¿«ç…§æ•°æ®ï¼Œæå‡æ€§èƒ½"""
    
    def __init__(self, ttl_seconds: int = 300):  # 5åˆ†é’ŸTTL
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.ttl = ttl_seconds
        self.logger = get_logger(__name__)
    
    def _get_cache_key(self, symbol: str, data_type: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{symbol}_{data_type}_{kwargs}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, symbol: str, data_type: str, **kwargs) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(symbol, data_type, **kwargs)
        
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            age = (datetime.now() - cached_item['timestamp']).total_seconds()
            
            if age < self.ttl:
                # åªåœ¨debugæ¨¡å¼è®°å½•å•ä¸ªç¼“å­˜å‘½ä¸­
                if self.logger.isEnabledFor(logging.DEBUG):
                    self.logger.debug(f"ç¼“å­˜å‘½ä¸­: {symbol} {data_type}")
                return cached_item['data']
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[cache_key]
        
        return None
    
    def set(self, symbol: str, data_type: str, data: Any, **kwargs):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(symbol, data_type, **kwargs)
        self.cache[cache_key] = {
            'data': data,
            'timestamp': datetime.now()
        }
        # åªåœ¨debugæ¨¡å¼è®°å½•å•ä¸ªç¼“å­˜è®¾ç½®
        if self.logger.isEnabledFor(logging.DEBUG):
            self.logger.debug(f"ç¼“å­˜è®¾ç½®: {symbol} {data_type}")
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.logger.info("æ•°æ®ç¼“å­˜å·²æ¸…ç©º")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            'cache_size': len(self.cache),
            'ttl_seconds': self.ttl
        }


class TechnicalSelectionStrategy(SelectionStrategy):
    """
    ä¸ comp_trategy_HK_v5.4 å…¼å®¹çš„æŠ€æœ¯é€‰è‚¡ç­–ç•¥å®ç°
    æ–°å¢è¯¦ç»†å…¥é€‰ç†ç”±åŠŸèƒ½
    """

    def __init__(self,
                 name: str = "technical_analysis",
                 config: Optional[StrategyConfig] = None,
                 broker: Optional[Any] = None,
                 stock_pool_manager: Optional[Any] = None):
        from quant_system.domain.strategies.base import StrategyType
        super().__init__(name, config, broker, stock_pool_manager)
        self.name = name
        self.config = config
        self.broker = broker
        self.stock_pool_manager = stock_pool_manager

        self.logger = get_logger(__name__)

        # åˆ†æå™¨ä¸è¯„åˆ†å™¨
        self.technical_analyzer = TechnicalAnalyzer()
        self.scorer = MultiDimensionScorer(broker) if broker is not None else MultiDimensionScorer()

        # å‚æ•°ï¼šå…¨å¸‚åœºåˆ†æ‰¹å¤„ç†é…ç½®ï¼ˆå·²ä¼˜åŒ–æ€§èƒ½ï¼‰
        self.parameters: Dict[str, Any] = {
            'batch_size': int(getattr(self.config, 'batch_size', 200)),
            'max_analysis_stocks': int(getattr(self.config, 'max_analysis_stocks', 5000)),
            'history_min_bars': int(getattr(self.config, 'history_min_bars', DEFAULT_HISTORY_BARS)),  # ä¼˜åŒ–ï¼šé»˜è®¤120
            'history_workers': int(getattr(self.config, 'history_workers', DEFAULT_HISTORY_WORKERS)),  # ä¼˜åŒ–ï¼šé»˜è®¤12ï¼Œé¿å…APIé¢‘ç‡é™åˆ¶
            'min_volume': int(getattr(self.config, 'min_volume', 2_000_000)),  # ä¼˜åŒ–ï¼šä»1Mæé«˜åˆ°2Mï¼Œæ›´ä¸¥æ ¼åˆç­›
            'min_price': float(getattr(self.config, 'min_price', 0.1)),
            'min_market_cap': float(getattr(self.config, 'min_market_cap', 2e8)),  # ä¼˜åŒ–ï¼šä»1e8æé«˜åˆ°2e8ï¼Œæ›´ä¸¥æ ¼åˆç­›
            'volatility_limit': float(getattr(self.config, 'volatility_limit', 0.15)),
            'w_tech': float(getattr(self.config, 'w_tech', 0.6)),
            'w_multi': float(getattr(self.config, 'w_multi', 0.4)),
            'score_threshold': float(getattr(self.config, 'score_threshold', 60.0)),
            'max_stocks': int(getattr(self.config, 'max_stocks', 50)),
            'priority_quota': int(getattr(self.config, 'priority_quota', 5)),
            'priority_boost': float(getattr(self.config, 'priority_boost', 10.0)),
            'allow_mock_market_data': bool(getattr(self.config, 'allow_mock_market_data', False)),
            'debug_relax_screening': bool(getattr(self.config, 'debug_relax_screening', True)),  # ä¸´æ—¶æ‰“å¼€ä»¥ä¾¿è°ƒè¯•
            'max_market_stocks': int(getattr(self.config, 'max_market_stocks', 10000)),  # æé«˜é™åˆ¶ï¼šæ”¯æŒå…¨å¸‚åœºæ­£è‚¡åˆ†æï¼ˆæ¸¯è‚¡ä¸»æ¿çº¦1500-2000åªæ­£è‚¡ï¼‰
            'analysis_batch_size': int(getattr(self.config, 'analysis_batch_size', 100)),  # ä¼˜åŒ–ï¼šä»200å‡å°‘åˆ°100
            'enable_progressive_filter': bool(getattr(self.config, 'enable_progressive_filter', True)),  # æ¸è¿›å¼ç­›é€‰
            'enable_cache': bool(getattr(self.config, 'enable_cache', True)),  # æ–°å¢ï¼šå¯ç”¨ç¼“å­˜
            'cache_ttl_seconds': int(getattr(self.config, 'cache_ttl_seconds', 300)),  # æ–°å¢ï¼šç¼“å­˜TTLï¼ˆ5åˆ†é’Ÿï¼‰
            # ä¸æ—§è„šæœ¬ä¸€è‡´çš„é˜ˆå€¼
            'volume_multiplier_for_signal': float(getattr(self.config, 'volume_multiplier_for_signal', 1.5)),
            'conv_threshold_percent': float(getattr(self.config, 'conv_threshold_percent', 3.0))
        }
        
        # åˆå§‹åŒ–æ•°æ®ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        if self.parameters.get('enable_cache', True):
            self.data_cache = DataCache(ttl_seconds=self.parameters.get('cache_ttl_seconds', 300))
            self.logger.info("âœ… æ•°æ®ç¼“å­˜å·²å¯ç”¨ï¼ˆTTL: 300ç§’ï¼‰")
        else:
            self.data_cache = None

        # ç®€å• sector mapï¼ˆå¯è¢« stock_pool_manager æ‰©å±•ï¼‰
        self.sector_map = self._initialize_sector_map()

        # æ€§èƒ½ä¸ç»Ÿè®¡
        self.performance_stats = {
            'total_runs': 0,
            'last_run_time': None,
            'candidates_examined': 0,
            'market_stocks_count': 0,
            'batches_processed': 0
        }

        self.logger.info(f"âœ… TechnicalSelectionStrategy åˆå§‹åŒ–å®Œæˆï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰: {self.name}")
        self.logger.info(f"   ä¼˜åŒ–å‚æ•°: Kçº¿={self.parameters['history_min_bars']}, å¹¶å‘={self.parameters['history_workers']}, æœ€å¤§åˆ†æ={self.parameters['max_market_stocks']}")

    def _initialize_sector_map(self) -> Dict[str, str]:
        return {
            '00700': 'ç§‘æŠ€', '09988': 'ç§‘æŠ€', '03690': 'ç§‘æŠ€',
            '00005': 'é‡‘è', '00941': 'ç”µä¿¡', '02318': 'é‡‘è',
            '01093': 'åŒ»è¯', '00883': 'èƒ½æº', '00388': 'é‡‘è'
        }

    # ---------- é¡¶å±‚å…¥å£ ----------
    def select_stocks(self, universe: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        å…¨å¸‚åœºé€‰è‚¡æµç¨‹ - å®Œæ•´ç‰ˆæœ¬
        æ”¯æŒå…¨å¸‚åœºé€‰è‚¡å’Œä¼ å…¥è‚¡ç¥¨æ± ä¸¤ç§æ¨¡å¼
        """
        start = datetime.now()
        self.logger.info("ğŸŒ å¼€å§‹æ‰§è¡Œå…¨å¸‚åœºæŠ€æœ¯é€‰è‚¡æµç¨‹ï¼ˆå®Œæ•´ç‰ˆï¼‰")
        self._ensure_debug_logging()

        # ğŸ¯ å…³é”®ä¿®å¤ï¼šå¤„ç†è‚¡ç¥¨æ± è¾“å…¥
        if universe is None or len(universe) == 0:
            self.logger.info("ğŸ“‹ universeå‚æ•°ä¸ºç©ºï¼Œä½¿ç”¨å…¨å¸‚åœºè·å–")
            market_universe = self._get_full_market_universe()
        elif len(universe) < 100:  # å¦‚æœè‚¡ç¥¨æ± å¾ˆå°ï¼Œè®°å½•è­¦å‘Šä½†ä»ä½¿ç”¨
            self.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å°è§„æ¨¡è‚¡ç¥¨æ±  ({len(universe)}åª)ï¼Œä½†ä»ä¼šè¿›è¡Œå…¨å¸‚åœºé€‰è‚¡")
            market_universe = self._get_full_market_universe()
        else:
            self.logger.info(f"ğŸ“‹ ä½¿ç”¨ä¼ å…¥çš„è‚¡ç¥¨åˆ—è¡¨: {len(universe)} åª")
            market_universe = universe

        if not market_universe:
            self.logger.warning("âš ï¸ æ— æ³•è·å–ä»»ä½•è‚¡ç¥¨åˆ—è¡¨ï¼Œè¿”å›ç©º")
            return []

        try:
            # 1) æ£€æŸ¥æ˜¯å¦éœ€è¦é™åˆ¶åˆ†ææ•°é‡ï¼ˆä»…å½“è‚¡ç¥¨æ•°é‡å¼‚å¸¸å¤šæ—¶ï¼‰
            # æ³¨æ„ï¼šç”±äºç°åœ¨åªè·å–æ­£è‚¡ï¼Œæ¸¯è‚¡ä¸»æ¿é€šå¸¸åªæœ‰1500-2000åªæ­£è‚¡ï¼Œä¸€èˆ¬ä¸éœ€è¦é™åˆ¶
            max_market_stocks = self.parameters.get('max_market_stocks', 10000)
            if len(market_universe) > max_market_stocks:
                original_count = len(market_universe)
                market_universe = market_universe[:max_market_stocks]
                self.logger.warning(f"âš ï¸ è‚¡ç¥¨æ•°é‡å¼‚å¸¸å¤šï¼Œé™åˆ¶åˆ†ææ•°é‡: {original_count} â†’ {max_market_stocks} åªè‚¡ç¥¨")
            else:
                self.logger.info(f"âœ… å…¨å¸‚åœºæ­£è‚¡æ•°é‡: {len(market_universe)} åªï¼ˆæœªé™åˆ¶ï¼‰")

            self.performance_stats['market_stocks_count'] = len(market_universe)
            self.logger.info(f"ğŸŒ æœ€ç»ˆåˆ†æè‚¡ç¥¨æ•°é‡: {len(market_universe)} åª")

            # 2) åˆ†æ‰¹è¿›è¡Œåˆç­›
            batch_size = self.parameters.get('analysis_batch_size', 200)
            all_candidates = []

            total_batches = (len(market_universe) + batch_size - 1) // batch_size
            self.logger.info(f"ğŸ”„ å¼€å§‹åˆ†æ‰¹åˆç­›ï¼Œå…± {total_batches} ä¸ªæ‰¹æ¬¡")

            for batch_num, batch_start in enumerate(range(0, len(market_universe), batch_size)):
                batch_end = min(batch_start + batch_size, len(market_universe))
                batch_symbols = market_universe[batch_start:batch_end]

                self.logger.info(
                    f"ğŸ”„ å¤„ç†åˆç­›æ‰¹æ¬¡ {batch_num + 1}/{total_batches}: {batch_start}-{batch_end}"
                )

                # åˆç­›å½“å‰æ‰¹æ¬¡
                batch_candidates = self._initial_snapshot_filter(batch_symbols)
                all_candidates.extend(batch_candidates)

                self.logger.info(f"   âœ… æ‰¹æ¬¡ {batch_num + 1} åˆç­›é€šè¿‡: {len(batch_candidates)} åª")

                # å¦‚æœå€™é€‰æ€»æ•°è¿‡å¤šï¼Œæå‰åœæ­¢
                if len(all_candidates) >= self.parameters.get('max_analysis_stocks', 5000):
                    self.logger.info(f"ğŸ“Š å€™é€‰è‚¡ç¥¨è¾¾åˆ°ä¸Šé™: {len(all_candidates)}ï¼Œåœæ­¢åˆç­›")
                    break

            self.logger.info(f"ğŸ” å…¨å¸‚åœºåˆç­›å®Œæˆ: æ€»å€™é€‰ {len(all_candidates)} åª")
            self.performance_stats['candidates_examined'] = len(all_candidates)

            if not all_candidates:
                self.logger.info("ğŸ“­ å…¨å¸‚åœºåˆç­›æœªå¾—åˆ°ä»»ä½•å€™é€‰ï¼Œè¿”å›ç©º")
                return []

            # 3) åˆ†æ‰¹è¿›è¡Œè¯¦ç»†åˆ†æ
            final_scored = []
            analysis_batch_size = min(100, batch_size)  # è¯¦ç»†åˆ†ææ‰¹æ¬¡æ›´å°

            analysis_batches = (len(all_candidates) + analysis_batch_size - 1) // analysis_batch_size
            self.logger.info(f"ğŸ” å¼€å§‹è¯¦ç»†åˆ†æï¼Œå…± {analysis_batches} ä¸ªæ‰¹æ¬¡")

            for batch_num, batch_start in enumerate(range(0, len(all_candidates), analysis_batch_size)):
                batch_end = min(batch_start + analysis_batch_size, len(all_candidates))
                batch_candidates = all_candidates[batch_start:batch_end]

                self.logger.info(
                    f"ğŸ” è¯¦ç»†åˆ†ææ‰¹æ¬¡ {batch_num + 1}/{analysis_batches}: {len(batch_candidates)} åª"
                )

                # å¹¶å‘è·å–å†å²æ•°æ®å’ŒæŠ€æœ¯åˆ†æ
                batch_indicators = self._parallel_fetch_and_calc(batch_candidates)

                # å¯¹å½“å‰æ‰¹æ¬¡è¿›è¡Œè¯„åˆ†
                batch_scored = self._score_batch_stocks(batch_indicators)
                final_scored.extend(batch_scored)

                self.logger.info(f"   âœ… æ‰¹æ¬¡ {batch_num + 1} åˆ†æå®Œæˆ: {len(batch_scored)} åª")

                self.performance_stats['batches_processed'] = batch_num + 1

                # æ˜¾ç¤ºè¿›åº¦
                progress = ((batch_num + 1) / analysis_batches) * 100
                if batch_num + 1 < analysis_batches:  # ä¸æ˜¯æœ€åä¸€æ‰¹æ—¶æ˜¾ç¤ºè¿›åº¦
                    self.logger.info(f"   ğŸ“Š åˆ†æè¿›åº¦: {progress:.1f}%")

            # 4) åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœå¹¶æ’åº
            if not final_scored:
                self.logger.info("ğŸ“­ è¯¦ç»†åˆ†ææœªå¾—åˆ°ä»»ä½•æœ‰æ•ˆç»“æœ")
                return []

            # æŒ‰è¯„åˆ†æ’åº
            ranked = sorted(final_scored, key=lambda x: x['score'], reverse=True)
            self.logger.info(f"ğŸ“Š å…¨å¸‚åœºåˆ†æå®Œæˆ: å…±åˆ†æ {len(ranked)} åªè‚¡ç¥¨")

            # æ˜¾ç¤ºè¯„åˆ†åˆ†å¸ƒ
            if ranked:
                scores = [item['score'] for item in ranked]
                self.logger.info(
                    f"ğŸ“ˆ è¯„åˆ†ç»Ÿè®¡ - æœ€é«˜: {max(scores):.1f}, æœ€ä½: {min(scores):.1f}, å¹³å‡: {sum(scores) / len(scores):.1f}")

            # 5) æ¿å—åˆ†æ•£ + åˆå¹¶ä¼˜å…ˆ
            diversified = self._select_diversified(ranked)
            self.logger.info(f"ğŸ¯ æ¿å—åˆ†æ•£å: {len(diversified)} åªè‚¡ç¥¨")

            # åˆå¹¶è‡ªé€‰è‚¡
            priority_list = self._get_priority_stocks()
            if priority_list:
                self.logger.info(f"â­ å‘ç° {len(priority_list)} åªè‡ªé€‰è‚¡")
            final = self._merge_priority_and_trim(diversified, priority_list)

            # æ ¼å¼åŒ–è¾“å‡º
            final_out = self._format_final_results(final)

            # ç»Ÿè®¡æ›´æ–°
            runtime = (datetime.now() - start).total_seconds()
            self.performance_stats['total_runs'] += 1
            self.performance_stats['last_run_time'] = datetime.now()

            self.logger.info(
                f"ğŸ¯ å…¨å¸‚åœºé€‰è‚¡å®Œæˆ: "
                f"è€—æ—¶ {runtime:.2f}s, "
                f"åˆ†æ {len(market_universe)}â†’{len(all_candidates)}â†’{len(ranked)}â†’{len(final_out)}"
            )
            
            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            if self.data_cache:
                cache_stats = self.data_cache.get_cache_stats()
                self.logger.info(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: ç¼“å­˜å¤§å°={cache_stats['cache_size']}, TTL={cache_stats['ttl_seconds']}ç§’")
            
            self._log_performance_summary(market_universe, all_candidates, ranked, final_out)

            # æ˜¾ç¤ºæœ€ç»ˆç»“æœæ‘˜è¦
            if final_out:
                self.logger.info("ğŸ† æœ€ç»ˆé€‰è‚¡ç»“æœ:")
                for i, stock in enumerate(final_out, 1):
                    self.logger.info(
                        f"  {i}. {stock['symbol']} {stock['name']} - "
                        f"è¯„åˆ†: {stock['score']:.1f} - "
                        f"ç†ç”±: {stock.get('reason', 'N/A')}"
                    )

            return final_out

        except Exception as e:
            self.logger.error(f"âŒ å…¨å¸‚åœºé€‰è‚¡æ‰§è¡Œå¤±è´¥: {e}")
            self.logger.debug(traceback.format_exc())
            return []

    def _detailed_analysis_optimized(self, candidates: List[str]) -> List[Dict[str, Any]]:
        """
        ä¼˜åŒ–çš„è¯¦ç»†åˆ†æ - å°æ‰¹æ¬¡å¤„ç†é¿å…å†…å­˜å’ŒAPIé™åˆ¶
        """
        analysis_batch_size = 50  # æ›´å°çš„åˆ†ææ‰¹æ¬¡
        final_scored = []

        self.logger.info(f"ğŸ”¬ å¼€å§‹è¯¦ç»†åˆ†æ {len(candidates)} åªå€™é€‰è‚¡ç¥¨")

        for batch_num, batch_start in enumerate(range(0, len(candidates), analysis_batch_size)):
            batch_end = min(batch_start + analysis_batch_size, len(candidates))
            batch_candidates = candidates[batch_start:batch_end]

            self.logger.info(
                f"ğŸ” è¯¦ç»†åˆ†ææ‰¹æ¬¡ {batch_num + 1}/{(len(candidates) + analysis_batch_size - 1) // analysis_batch_size}")

            # å¹¶å‘è·å–æ•°æ®å’ŒæŠ€æœ¯åˆ†æ
            batch_indicators = self._parallel_fetch_and_calc(batch_candidates)

            # è¯„åˆ†
            batch_scored = self._score_batch_stocks(batch_indicators)
            final_scored.extend(batch_scored)

            self.logger.info(f"   âœ… æ‰¹æ¬¡ {batch_num + 1} åˆ†æå®Œæˆ: {len(batch_scored)} åª")

            # è¿›åº¦å’Œå†…å­˜ç›‘æ§
            progress = (batch_end / len(candidates)) * 100
            self.logger.info(f"   ğŸ“Š åˆ†æè¿›åº¦: {progress:.1f}% ({batch_end}/{len(candidates)})")

        return final_scored

    def _get_full_market_universe(self) -> List[str]:
        """
        è·å–å…¨å¸‚åœºæ­£è‚¡åˆ—è¡¨ï¼ˆä»…æ­£è‚¡ï¼Œä¸åŒ…å«è¡ç”Ÿå“å’ŒæŒ‡æ•°ï¼‰
        
        åªè·å– SecurityType.STOCK ç±»å‹çš„è‚¡ç¥¨ï¼Œç¡®ä¿åˆ†æçš„æ˜¯çœŸæ­£çš„æ­£è‚¡ã€‚
        è¡ç”Ÿå“ï¼ˆæƒè¯ã€çªè½®ç­‰ï¼‰å’ŒæŒ‡æ•°ä¼šåœ¨åç»­å¿«ç…§è·å–æ—¶è¢«è¿›ä¸€æ­¥è¿‡æ»¤ã€‚
        """
        if not self.broker:
            self.logger.warning("broker ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []

        try:
            from futu import Market, SecurityType, RET_OK
            all_stocks = []

            # åªè·å–æ­£è‚¡ç±»å‹ï¼Œä¸åŒ…å«æƒè¯ã€æŒ‡æ•°ç­‰è¡ç”Ÿå“
            market_types = [
                (Market.HK, SecurityType.STOCK),  # ä»…è·å–æ­£è‚¡
            ]

            for market, sec_type in market_types:
                try:
                    # åˆ†æ‰¹è·å–ï¼Œé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤š
                    ret, df = self.broker.get_stock_basicinfo(market, sec_type)
                    if ret == RET_OK and df is not None and not df.empty:
                        codes = df['code'].astype(str).tolist()
                        codes = [c for c in codes if isinstance(c, str) and c.strip()]
                        normalized = [c if c.startswith('HK.') else f"HK.{c}" for c in codes]
                        all_stocks.extend(normalized)
                        self.logger.info(f"ğŸ“ˆ è·å– {market}.{sec_type}ï¼ˆæ­£è‚¡ï¼‰: {len(normalized)} åªè‚¡ç¥¨")
                except Exception as e:
                    self.logger.debug(f"è·å– {market}.{sec_type} å¤±è´¥: {e}")
                    continue

            # å»é‡
            all_stocks = list(set(all_stocks))
            self.logger.info(f"ğŸŒ å…¨å¸‚åœºæ­£è‚¡æ€»æ•°: {len(all_stocks)} åªï¼ˆå·²æ’é™¤è¡ç”Ÿå“å’ŒæŒ‡æ•°ï¼‰")

            return all_stocks

        except Exception as e:
            self.logger.error(f"è·å–å…¨å¸‚åœºè‚¡ç¥¨å¤±è´¥: {e}")
            self.logger.debug(traceback.format_exc())
            return []

    def _score_batch_stocks(self, indicators_map: Dict[str, Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å¯¹ä¸€æ‰¹è‚¡ç¥¨è¿›è¡Œè¯„åˆ†
        """
        scored = []

        for sym, payload in indicators_map.items():
            try:
                kline = payload.get('kline')
                snapshot = payload.get('snapshot', {})

                if kline is None or kline.empty:
                    continue

                # technical analyzer åŸºç¡€ç»“æœ
                tech_res = self.technical_analyzer.analyze_conditions(kline)
                # multi-dim score
                multi_res = self.scorer.calculate_comprehensive_score(sym, kline, snapshot)

                # åˆå¹¶å¾—åˆ†
                tech_base = float(tech_res.get('total_score', 0) or 0)
                multi_score = float(multi_res.get('final_score', 0) or 0)
                composite = self.parameters['w_tech'] * tech_base + self.parameters['w_multi'] * multi_score

                # åŠ å…¥ volatility æƒ©ç½š
                vol = float(payload.get('indicators', {}).get('volatility', 0) or 0)
                if vol > self.parameters['volatility_limit']:
                    composite -= min(30.0, (vol - self.parameters['volatility_limit']) * 200.0)

                # ç”Ÿæˆè¯¦ç»†çš„å…¥é€‰ç†ç”±
                reason = self._generate_detailed_reason(sym, tech_res, multi_res, composite, vol, snapshot)

                scored.append({
                    'symbol': sym,
                    'score': float(composite),
                    'tech_total_score': tech_base,
                    'multi_score': multi_score,
                    'indicators': payload.get('indicators', {}),
                    'kline': kline,
                    'snapshot': snapshot,
                    'reason': reason
                })

                # è®°å½•è¯¦ç»†æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
                if self.parameters.get('debug_relax_screening'):
                    name = snapshot.get('name', sym)
                    self.logger.debug(
                        f"   ğŸ“Š {sym} {name}: æŠ€æœ¯{tech_base:.1f}, å¤šç»´{multi_score:.1f}, ç»¼åˆ{composite:.1f}")

            except Exception as e:
                self.logger.debug(f"è¯„åˆ†å¼‚å¸¸ {sym}: {e}")
                continue

        return scored

    def _get_priority_stocks(self) -> List[str]:
        """è·å–ä¼˜å…ˆè‚¡ç¥¨åˆ—è¡¨"""
        priority_list = []
        try:
            if self.stock_pool_manager:
                # å°è¯•è·å–ä¸åŒçš„ä¼˜å…ˆæ± 
                priority_pools = ['priority', 'default', 'favorites', 'watchlist']
                for pool_name in priority_pools:
                    try:
                        if hasattr(self.stock_pool_manager, 'get_stocks_from_pool'):
                            stocks = self.stock_pool_manager.get_stocks_from_pool(pool_name)
                            if stocks:
                                priority_list.extend(stocks)
                                self.logger.info(f"ğŸ¯ ä» {pool_name} æ± è·å– {len(stocks)} åªä¼˜å…ˆè‚¡")
                                break
                    except Exception:
                        continue
        except Exception as e:
            self.logger.debug(f"è·å–ä¼˜å…ˆè‚¡å¤±è´¥: {e}")

        return list(set(priority_list))  # å»é‡

    def _format_final_results(self, final: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–æœ€ç»ˆç»“æœ"""
        final_out = []
        for item in final:
            snap = item.get('snapshot', {}) or {}
            final_out.append({
                'symbol': item['symbol'],
                'name': snap.get('name', item['symbol']),
                'score': float(item.get('score', 0)),
                'current_price': snap.get('last_price', 0),
                'change_rate': snap.get('change_rate', 0),
                'indicators': item.get('indicators', {}),
                'reason': item.get('reason')
            })
        return final_out

    def _log_performance_summary(self, market_universe: List[str], candidates: List[str],
                                 scored: List[Dict], final: List[Dict]):
        """è®°å½•æ€§èƒ½æ‘˜è¦"""
        if scored:
            avg_score = sum(item['score'] for item in scored) / len(scored)
            high_score_count = sum(1 for item in scored if item['score'] >= 80)
            medium_score_count = sum(1 for item in scored if item['score'] >= 60)
        else:
            avg_score = 0
            high_score_count = 0
            medium_score_count = 0

        self.logger.info("ğŸ“ˆ å…¨å¸‚åœºé€‰è‚¡æ€§èƒ½æ‘˜è¦:")
        self.logger.info(f"   â€¢ å¸‚åœºè‚¡ç¥¨: {len(market_universe)}")
        self.logger.info(f"   â€¢ åˆç­›å€™é€‰: {len(candidates)}")
        self.logger.info(f"   â€¢ è¯¦ç»†åˆ†æ: {len(scored)}")
        self.logger.info(f"   â€¢ æœ€ç»ˆå…¥é€‰: {len(final)}")
        self.logger.info(f"   â€¢ å¹³å‡è¯„åˆ†: {avg_score:.1f}")
        self.logger.info(f"   â€¢ é«˜åˆ†è‚¡ç¥¨(â‰¥80): {high_score_count}åª")
        self.logger.info(f"   â€¢ è‰¯å¥½è‚¡ç¥¨(â‰¥60): {medium_score_count}åª")
        self.logger.info(f"   â€¢ å¤„ç†æ‰¹æ¬¡: {self.performance_stats['batches_processed']}")


    # æ›¿æ¢ _generate_detailed_reason æ–¹æ³•åŠå…¶ç›¸å…³æ–¹æ³•

    def _generate_detailed_reason(self, symbol: str, tech_res: Dict, multi_res: Dict,
                                  composite_score: float, volatility: float, snapshot: Dict) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„å…¥é€‰ç†ç”± - ä¼˜åŒ–ç‰ˆ
        æ›´ç§¯æåœ°å±•ç¤ºè‚¡ç¥¨çš„ä¼˜ç‚¹
        """
        reasons = []

        try:
            # 1. æŠ€æœ¯åˆ†æç†ç”± - ä¼˜å…ˆå±•ç¤ºæ­£é¢ä¿¡å·
            tech_reasons = self._extract_tech_reasons(tech_res)
            reasons.extend(tech_reasons)

            # 2. å¤šç»´åº¦è¯„åˆ†ç†ç”± - åªå±•ç¤ºä¼˜ç§€å’Œè‰¯å¥½çš„ç»´åº¦
            multi_reasons = self._extract_multi_reasons(multi_res)
            reasons.extend(multi_reasons)

            # 3. ä»·æ ¼è¡¨ç°ç†ç”± - ä¼˜å…ˆå±•ç¤ºæ­£é¢è¡¨ç°
            price_reasons = self._extract_price_reasons(snapshot)
            reasons.extend(price_reasons)

            # 4. ç»¼åˆè¯„åˆ†ç†ç”± - æ ¹æ®å®é™…åˆ†æ•°è°ƒæ•´æè¿°
            score_reason = self._get_score_reason(composite_score)
            reasons.append(score_reason)

            # 5. æ³¢åŠ¨ç‡ç‰¹å¾ - ä¼˜åŒ–æè¿°
            vol_reason = self._get_volatility_reason(volatility)
            if "ä½æ³¢åŠ¨" in vol_reason or "æ­£å¸¸" in vol_reason:
                reasons.append(vol_reason)

            # 6. ç‰¹æ®Šä¿¡å· - åªå±•ç¤ºæ­£é¢ä¿¡å·
            special_signals = self._get_special_signals(tech_res, multi_res)
            reasons.extend(special_signals)

            # å¦‚æœç†ç”±ä¸è¶³ï¼Œæ·»åŠ ä¸€äº›é€šç”¨çš„æ­£é¢æè¿°
            if len(reasons) < 2:
                if composite_score >= 60:
                    reasons.append("æŠ€æœ¯é¢è‰¯å¥½")
                elif composite_score >= 40:
                    reasons.append("å…·å¤‡æ½œåŠ›")
                else:
                    reasons.append("è§‚å¯Ÿæ ‡çš„")

            # é™åˆ¶ç†ç”±æ•°é‡ï¼Œä¼˜å…ˆä¿ç•™æ­£é¢ç†ç”±
            if len(reasons) > 4:
                # ä¼˜å…ˆä¿ç•™æ­£é¢ç†ç”±
                positive_keywords = ['é‡‘å‰', 'å¤šå¤´', 'çªç ´', 'æ”¾é‡', 'ä¼˜ç§€', 'è‰¯å¥½', 'ä¸Šæ¶¨', 'é«˜åˆ†', 'å…±æŒ¯']
                positive_reasons = [r for r in reasons if any(keyword in r for keyword in positive_keywords)]
                other_reasons = [r for r in reasons if r not in positive_reasons]
                main_reasons = positive_reasons[:3] + other_reasons[:1]
            else:
                main_reasons = reasons

            return " | ".join(main_reasons) if main_reasons else "ç»¼åˆæŠ€æœ¯åˆ†æ"

        except Exception as e:
            self.logger.debug(f"ç”Ÿæˆå…¥é€‰ç†ç”±å¤±è´¥ {symbol}: {e}")
            return "æŠ€æœ¯åˆ†æé€šè¿‡"

    def _extract_tech_reasons(self, tech_res: Dict) -> List[str]:
        """ä»æŠ€æœ¯åˆ†æç»“æœæå–ç†ç”± - ä¼˜åŒ–ç‰ˆ"""
        reasons = []

        try:
            # æ£€æŸ¥æŠ€æœ¯åˆ†æä¸­çš„å…³é”®ä¿¡å·
            conditions = tech_res.get('conditions', {})

            # MACD ä¿¡å· - åªå…³æ³¨é‡‘å‰
            macd_signal = conditions.get('macd_signal')
            if macd_signal == 'golden_cross':
                reasons.append("MACDé‡‘å‰")

            # å‡çº¿æ’åˆ— - åªå…³æ³¨å¤šå¤´
            ma_arrangement = conditions.get('ma_arrangement')
            if ma_arrangement == 'bullish':
                reasons.append("å‡çº¿å¤šå¤´")

            # RSI çŠ¶æ€ - ä¼˜åŒ–æè¿°
            rsi_status = conditions.get('rsi_status')
            if rsi_status == 'oversold':
                reasons.append("RSIè¶…å–æœ‰æœºä¼š")
            elif rsi_status == 'normal':
                reasons.append("RSIå¥åº·")

            # æˆäº¤é‡ä¿¡å· - åªå…³æ³¨æ”¾é‡
            volume_signal = conditions.get('volume_signal')
            if volume_signal == 'volume_breakout':
                reasons.append("é‡ä»·é…åˆ")

            # è¶‹åŠ¿çŠ¶æ€ - åªå…³æ³¨ä¸Šå‡è¶‹åŠ¿
            trend = conditions.get('trend')
            if trend == 'uptrend':
                reasons.append("è¶‹åŠ¿å‘ä¸Š")
            elif trend == 'sideways':
                reasons.append("éœ‡è¡æ•´ç†")

            # çªç ´ä¿¡å·
            if conditions.get('breakout'):
                reasons.append("å½¢æ€çªç ´")

        except Exception as e:
            self.logger.debug(f"æå–æŠ€æœ¯ç†ç”±å¤±è´¥: {e}")

        return reasons

    def _extract_multi_reasons(self, multi_res: Dict) -> List[str]:
        """ä»å¤šç»´åº¦è¯„åˆ†æå–ç†ç”± - ä¼˜åŒ–ç‰ˆ"""
        reasons = []

        try:
            scores = multi_res.get('dimension_scores', {})

            # åªå±•ç¤ºè¯„åˆ†è¾ƒé«˜çš„ç»´åº¦
            dimension_names = {
                'momentum': 'åŠ¨é‡', 'value': 'ä¼°å€¼', 'growth': 'æˆé•¿',
                'quality': 'è´¨é‡', 'risk': 'é£æ§', 'liquidity': 'æµåŠ¨æ€§'
            }

            for dimension, score in scores.items():
                dim_name = dimension_names.get(dimension, dimension)
                if score >= 75:
                    reasons.append(f"{dim_name}ä¼˜ç§€")
                elif score >= 60:
                    reasons.append(f"{dim_name}è‰¯å¥½")

            # ç‰¹æ®Šç»´åº¦å¤„ç† - ä¼˜åŒ–æè¿°
            momentum_score = scores.get('momentum', 0)
            if momentum_score >= 70:
                reasons.append("åŠ¨é‡å¼ºåŠ²")
            elif momentum_score >= 50:
                reasons.append("åŠ¨é‡ç¨³å®š")

            value_score = scores.get('value', 0)
            if value_score >= 70:
                reasons.append("ä¼°å€¼å¸å¼•")

        except Exception as e:
            self.logger.debug(f"æå–å¤šç»´åº¦ç†ç”±å¤±è´¥: {e}")

        return reasons

    def _extract_price_reasons(self, snapshot: Dict) -> List[str]:
        """ä»ä»·æ ¼æ•°æ®æå–ç†ç”± - ä¼˜åŒ–ç‰ˆ"""
        reasons = []

        try:
            change_rate = snapshot.get('change_rate', 0)
            amplitude = snapshot.get('amplitude', 0)

            # æ¶¨è·Œå¹…ç†ç”± - ä¼˜åŒ–æè¿°
            if change_rate > 0.03:
                reasons.append("ä»·æ ¼å¼ºåŠ¿")
            elif change_rate > 0:
                reasons.append("ä»·æ ¼ä¼ç¨³")
            elif change_rate >= -0.02:
                reasons.append("ä»·æ ¼ç¨³å®š")

            # æŒ¯å¹…ç†ç”± - ä¼˜åŒ–æè¿°
            if 0.03 <= amplitude <= 0.08:
                reasons.append("äº¤æŠ•æ´»è·ƒ")
            elif amplitude < 0.03:
                reasons.append("èµ°åŠ¿ç¨³å¥")

        except Exception as e:
            self.logger.debug(f"æå–ä»·æ ¼ç†ç”±å¤±è´¥: {e}")

        return reasons

    def _get_score_reason(self, composite_score: float) -> str:
        """æ ¹æ®ç»¼åˆè¯„åˆ†ç»™å‡ºè¯„ä»· - ä¼˜åŒ–ç‰ˆ"""
        if composite_score >= 80:
            return "ç»¼åˆä¼˜ç§€"
        elif composite_score >= 60:
            return "è¡¨ç°è‰¯å¥½"
        elif composite_score >= 40:
            return "å…·å¤‡æ½œåŠ›"
        else:
            return "è§‚å¯Ÿæ ‡çš„"

    def _get_volatility_reason(self, volatility: float) -> str:
        """æ³¢åŠ¨ç‡ç‰¹å¾ - ä¼˜åŒ–ç‰ˆ"""
        if volatility < 0.015:
            return "èµ°åŠ¿ç¨³å¥"
        elif volatility < 0.03:
            return "æ³¢åŠ¨åˆç†"
        elif volatility < 0.05:
            return "æ´»è·ƒåº¦é«˜"
        else:
            return "æ³¢åŠ¨è¾ƒå¤§"

    def _get_special_signals(self, tech_res: Dict, multi_res: Dict) -> List[str]:
        """ç‰¹æ®Šä¿¡å·æ£€æµ‹ - ä¼˜åŒ–ç‰ˆ"""
        signals = []

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼ºçƒˆçš„ä¹°å…¥ä¿¡å·
            conditions = tech_res.get('conditions', {})

            # å¤šé‡æŠ€æœ¯æŒ‡æ ‡å…±æŒ¯
            bullish_signals = 0
            if conditions.get('macd_signal') == 'golden_cross':
                bullish_signals += 1
            if conditions.get('ma_arrangement') == 'bullish':
                bullish_signals += 1
            if conditions.get('trend') == 'uptrend':
                bullish_signals += 1

            if bullish_signals >= 2:
                signals.append("æŠ€æœ¯é¢å…±æŒ¯")
            elif bullish_signals >= 1:
                signals.append("æŠ€æœ¯æŒ‡æ ‡å‘å¥½")

            # æ£€æŸ¥è¶…å–åå¼¹æœºä¼š
            if (conditions.get('rsi_status') == 'oversold' and
                    conditions.get('trend') != 'downtrend'):
                signals.append("è¶…å–åå¼¹æœºä¼š")

            # æ£€æŸ¥å¤šç»´åº¦ä¼˜ç§€
            scores = multi_res.get('dimension_scores', {})
            excellent_dims = sum(1 for score in scores.values() if score >= 75)
            good_dims = sum(1 for score in scores.values() if score >= 60)

            if excellent_dims >= 2:
                signals.append("å¤šç»´åº¦ä¼˜ç§€")
            elif good_dims >= 3:
                signals.append("å¤šç»´åº¦è‰¯å¥½")

        except Exception as e:
            self.logger.debug(f"æ£€æµ‹ç‰¹æ®Šä¿¡å·å¤±è´¥: {e}")

        return signals

    # ---------- è¾…åŠ©æ–¹æ³•ï¼šå¸‚åœºåˆ—è¡¨ & åˆç­› ----------
    def _get_market_universe(self) -> List[str]:
        """
        å°½å¯èƒ½è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ï¼Œä¼˜å…ˆä½¿ç”¨ broker.get_stock_basicinfo
        è¿”å›æ ‡å‡†åŒ–ä¸º 'HK.XXXX' çš„ä»£ç åˆ—è¡¨
        """
        if not self.broker or not hasattr(self.broker, 'get_stock_basicinfo'):
            self.logger.warning("broker ä¸å¯ç”¨æˆ–ä¸æ”¯æŒ get_stock_basicinfoï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []

        try:
            # futu é£æ ¼: ret, df
            from futu import Market, SecurityType, RET_OK
            ret, df = self.broker.get_stock_basicinfo(Market.HK, SecurityType.STOCK)
            if ret == RET_OK and df is not None and not df.empty:
                codes = df['code'].astype(str).tolist()
                codes = [c for c in codes if isinstance(c, str) and c.strip()]
                normalized = [c if c.startswith('HK.') else f"HK.{c}" for c in codes]
                return normalized
            else:
                self.logger.warning("broker.get_stock_basicinfo æœªè¿”å›æœ‰æ•ˆæ•°æ®")
                return []
        except Exception as e:
            self.logger.error(f"è·å–å¸‚åœºè‚¡ç¥¨å¤±è´¥: {e}")
            self.logger.debug(traceback.format_exc())
            return []

    def _initial_snapshot_filter(self, universe: List[str]) -> List[str]:
        batch = int(self.parameters.get('batch_size', DEFAULT_BATCH_SIZE))
        candidates = []
        max_cand = int(self.parameters.get('max_analysis_stocks', DEFAULT_MAX_ANALYSIS))
        vol_mult = float(self.parameters.get('volume_multiplier_for_signal', 1.5))
        min_vol = int(self.parameters.get('min_volume', 2_000_000))  # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        min_price = float(self.parameters.get('min_price', 0.1))
        min_mcap = float(self.parameters.get('min_market_cap', 2e8))  # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼

        total = len(universe)
        # ç­›é€‰ç»Ÿè®¡ï¼ˆæ‰¹é‡æ—¥å¿—ä¼˜åŒ–ï¼‰
        filter_stats = {
            'price_rejected': 0,
            'volume_rejected': 0,
            'suspended': 0,
            'market_cap_rejected': 0,
            'change_rate_rejected': 0,
            'zero_market_cap': 0,
            'exceptions': 0
        }
        
        for i in range(0, total, batch):
            chunk = universe[i:i + batch]
            snap = self._safe_get_market_snapshot(chunk)
            if not snap:
                if self.logger.isEnabledFor(logging.DEBUG):
                    self.logger.debug(f"[SNAPSHOT] æ‰¹æ¬¡ {i // batch + 1} æœªè·å–åˆ°å¿«ç…§")
                continue

            for s in chunk:
                d = snap.get(s, {})
                if not d:
                    continue
                try:
                    last = float(d.get('last_price', 0) or 0)
                    vol = int(d.get('volume', 0) or 0)

                    # ğŸ”§ ä¿®å¤ï¼šæ”¹è¿›å¸‚å€¼æ•°æ®è·å–é€»è¾‘
                    # å°è¯•å¤šç§å¯èƒ½çš„å¸‚å€¼å­—æ®µ
                    mcap = 0.0
                    market_cap_fields = [
                        'market_cap', 'total_market_val', 'total_market_cap',
                        'market_value', 'capitalization', 'circulating_market_val'
                    ]

                    for field in market_cap_fields:
                        field_value = d.get(field, 0)
                        if field_value and float(field_value) > 0:
                            mcap = float(field_value)
                            # åªåœ¨debugæ¨¡å¼è®°å½•å•ä¸ªå¸‚å€¼è·å–
                            if self.logger.isEnabledFor(logging.DEBUG) and self.parameters.get('debug_relax_screening'):
                                self.logger.debug(f"ğŸ’° {s} ä½¿ç”¨ {field} å­—æ®µè·å–å¸‚å€¼: {mcap}")
                            break

                    # å¦‚æœæ‰€æœ‰å­—æ®µéƒ½æ˜¯0ï¼Œè®°å½•è­¦å‘Šï¼ˆä½†åªè®°å½•ä¸€æ¬¡æˆ–æ±‡æ€»ï¼‰
                    if mcap == 0:
                        filter_stats['zero_market_cap'] += 1
                        if filter_stats['zero_market_cap'] <= 3:  # åªè®°å½•å‰3ä¸ª
                            self.logger.warning(f"âš ï¸ {s} æ‰€æœ‰å¸‚å€¼å­—æ®µå‡ä¸º0ï¼Œæ£€æŸ¥å¯ç”¨å­—æ®µ: {list(d.keys())}")

                    trade_status = d.get('trade_status', None)
                    change_rate = abs(float(d.get('change_rate', 0) or 0))

                    # åŸºç¡€è¿‡æ»¤ï¼šä»·æ ¼ã€volumeã€çŠ¶æ€ã€å¸‚å€¼ï¼ˆæ‰¹é‡ç»Ÿè®¡ï¼Œä¸é€æ¡è®°å½•ï¼‰
                    if last <= 0 or last < min_price:
                        filter_stats['price_rejected'] += 1
                        continue
                    if vol < min_vol:
                        filter_stats['volume_rejected'] += 1
                        continue
                    if trade_status == 'SUSPENDED':
                        filter_stats['suspended'] += 1
                        continue
                    if mcap < min_mcap:
                        filter_stats['market_cap_rejected'] += 1
                        continue
                    
                    # ä¼˜åŒ–ï¼šè¿‡æ»¤æ‰å•æ—¥æ¶¨è·Œå¹…è¿‡å¤§çš„è‚¡ç¥¨ï¼ˆå‡å°‘å¼‚å¸¸æ³¢åŠ¨ï¼‰
                    if change_rate > 0.15:  # è¿‡æ»¤å•æ—¥æ¶¨è·Œå¹…è¶…è¿‡15%çš„
                        filter_stats['change_rate_rejected'] += 1
                        continue

                    # é€šè¿‡åˆç­›ï¼ŒåŠ å…¥å€™é€‰
                    candidates.append(s)

                    # è‹¥å€™é€‰è¿‡å¤šï¼Œæˆªæ–­ï¼ˆæ¨¡æ‹Ÿæ—§è„šæœ¬ä¸­å¯¹å€™é€‰æ± çš„é™åˆ¶ï¼‰
                    if len(candidates) >= max_cand:
                        # è¾“å‡ºç­›é€‰ç»Ÿè®¡
                        if self.logger.isEnabledFor(logging.DEBUG):
                            self.logger.debug(f"åˆç­›ç»Ÿè®¡: ä»·æ ¼æ‹’ç»={filter_stats['price_rejected']}, "
                                            f"æˆäº¤é‡æ‹’ç»={filter_stats['volume_rejected']}, "
                                            f"åœç‰Œ={filter_stats['suspended']}, "
                                            f"å¸‚å€¼æ‹’ç»={filter_stats['market_cap_rejected']}, "
                                            f"æ¶¨è·Œå¹…æ‹’ç»={filter_stats['change_rate_rejected']}")
                        return candidates

                except Exception as e:
                    filter_stats['exceptions'] += 1
                    if self.logger.isEnabledFor(logging.DEBUG):
                        self.logger.debug(f"[åˆç­›å¼‚å¸¸] {s}: {e}")
                    continue

        # è¾“å‡ºæœ€ç»ˆç­›é€‰ç»Ÿè®¡
        if self.logger.isEnabledFor(logging.DEBUG):
            self.logger.debug(f"åˆç­›å®Œæˆç»Ÿè®¡: ä»·æ ¼æ‹’ç»={filter_stats['price_rejected']}, "
                            f"æˆäº¤é‡æ‹’ç»={filter_stats['volume_rejected']}, "
                            f"åœç‰Œ={filter_stats['suspended']}, "
                            f"å¸‚å€¼æ‹’ç»={filter_stats['market_cap_rejected']}, "
                            f"æ¶¨è·Œå¹…æ‹’ç»={filter_stats['change_rate_rejected']}, "
                            f"é›¶å¸‚å€¼={filter_stats['zero_market_cap']}, "
                            f"å¼‚å¸¸={filter_stats['exceptions']}, "
                            f"é€šè¿‡={len(candidates)}")

        return candidates

    def _safe_get_market_snapshot(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        åˆ†æ‰¹è·å–å¸‚åœºå¿«ç…§ï¼Œæ¯æ‰¹ä¸è¶…è¿‡200åª
        å·²ä¼˜åŒ–ï¼šæ·»åŠ ç¼“å­˜æ”¯æŒ
        """
        if not symbols:
            return {}

        # æ£€æŸ¥ç¼“å­˜
        cached_results = {}
        symbols_to_fetch = []
        
        if self.data_cache:
            for symbol in symbols:
                cached_snapshot = self.data_cache.get(symbol, 'snapshot')
                if cached_snapshot is not None:
                    cached_results[symbol] = cached_snapshot
                else:
                    symbols_to_fetch.append(symbol)
        else:
            symbols_to_fetch = symbols

        if not self.broker or not hasattr(self.broker, 'get_market_snapshot'):
            if self.parameters.get('allow_mock_market_data'):
                mock_data = self._generate_mock_market_data(symbols_to_fetch)
                # å­˜å…¥ç¼“å­˜
                if self.data_cache and mock_data:
                    for symbol, data in mock_data.items():
                        self.data_cache.set(symbol, 'snapshot', data)
                cached_results.update(mock_data)
                return cached_results
            return cached_results

        try:
            # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š200åª
            batch_size = 200
            all_results = {}

            total_batches = (len(symbols_to_fetch) - 1) // batch_size + 1
            failed_batches = 0
            
            for i in range(0, len(symbols_to_fetch), batch_size):
                batch_symbols = symbols_to_fetch[i:i + batch_size]
                if self.logger.isEnabledFor(logging.DEBUG):
                    self.logger.debug(f"ğŸ“¡ è·å–å¿«ç…§æ‰¹æ¬¡ {i // batch_size + 1}/{total_batches}: {len(batch_symbols)} åª")

                try:
                    res = self.broker.get_market_snapshot(batch_symbols)
                    if res:
                        all_results.update(res)
                        # å­˜å…¥ç¼“å­˜
                        if self.data_cache:
                            for symbol, snapshot in res.items():
                                self.data_cache.set(symbol, 'snapshot', snapshot)

                    # æ·»åŠ å°å»¶è¿Ÿé¿å…APIé™åˆ¶
                    import time
                    time.sleep(0.1)

                except Exception as e:
                    failed_batches += 1
                    self.logger.warning(f"å¿«ç…§æ‰¹æ¬¡ {i // batch_size + 1} å¤±è´¥: {e}")
                    continue

            # åˆå¹¶ç¼“å­˜å’Œè·å–çš„ç»“æœ
            cached_results.update(all_results)
            cache_count = len(cached_results) - len(all_results)
            self.logger.info(f"âœ… å¿«ç…§è·å–å®Œæˆ: {len(cached_results)}/{len(symbols)} åªè‚¡ç¥¨ï¼ˆç¼“å­˜: {cache_count}, å¤±è´¥æ‰¹æ¬¡: {failed_batches}ï¼‰")
            return cached_results

        except Exception as e:
            self.logger.error(f"get_market_snapshot å¼‚å¸¸: {e}")
            if self.parameters.get('allow_mock_market_data'):
                mock_data = self._generate_mock_market_data(symbols_to_fetch)
                cached_results.update(mock_data)
                return cached_results
            return cached_results

    # ---------- å¹¶å‘æ‹‰å†å²ä¸æŒ‡æ ‡è®¡ç®— ----------
    def _parallel_fetch_and_calc(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        å¹¶å‘è·å–å†å²Kçº¿ - ä¼˜åŒ–ç‰ˆï¼Œæ§åˆ¶å¹¶å‘æ•°é‡
        å·²ä¼˜åŒ–ï¼šæé«˜å¹¶å‘æ•°å’Œæ‰¹æ¬¡å¤§å°
        """
        results = {}
        # è‡ªé€‚åº”å¹¶å‘æ§åˆ¶ï¼šæ ¹æ®APIé™åˆ¶ï¼ˆæ¯30ç§’60æ¬¡ï¼‰åŠ¨æ€è°ƒæ•´
        # ä¿å®ˆä¼°è®¡ï¼šæ¯ä¸ªè¯·æ±‚çº¦0.5ç§’ï¼Œ12ä¸ªå¹¶å‘æ›´å®‰å…¨ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
        workers = min(self.parameters.get('history_workers', DEFAULT_HISTORY_WORKERS), 10)  # æœ€å¤§10ï¼Œä¸¥æ ¼éµå®ˆAPIé™åˆ¶ï¼ˆæ¯30ç§’60æ¬¡ï¼‰
        history_bars = self.parameters.get('history_min_bars', DEFAULT_HISTORY_BARS)

        # æ§åˆ¶æ¯æ‰¹å¤„ç†æ•°é‡
        batch_size = 100  # ä¼˜åŒ–ï¼šä»50å¢åŠ åˆ°100ï¼Œæé«˜ååé‡

        def task(sym: str):
            try:
                # è·å–å¿«ç…§ï¼ˆå•åªè‚¡ç¥¨ï¼Œä¸å—200é™åˆ¶ï¼‰
                snap = self._safe_get_market_snapshot([sym]).get(sym, {})

                # è·å–å†å²Kçº¿
                kline = self._safe_get_history_kline(sym, history_bars)
                if kline is None or len(kline) < history_bars:
                    if self.parameters.get('allow_mock_market_data'):
                        kline = self._generate_mock_kline(sym, bars=history_bars)
                    else:
                        return sym, None

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                indicators = {}
                try:
                    ta_data = self.technical_analyzer._calculate_technical_indicators(kline.copy())
                    indicators.update({
                        'volatility': float(ta_data.get('CONV', pd.Series([0])).iloc[-1]),
                        'ma_mean': float(ta_data.get('MA_MEAN', pd.Series([0])).iloc[-1]),
                        'macd_golden': bool(ta_data.get('MACD_GOLDEN', pd.Series([False])).iloc[-1])
                    })
                except Exception as e:
                    self.logger.debug(f"æŒ‡æ ‡è®¡ç®—å¤±è´¥ {sym}: {e}")

                return sym, {'kline': kline, 'snapshot': snap, 'indicators': indicators}

            except Exception as e:
                self.logger.debug(f"å¹¶å‘ä»»åŠ¡å¤±è´¥ {sym}: {e}")
                return sym, None

        # åˆ†æ‰¹æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        for batch_start in range(0, len(symbols), batch_size):
            batch_symbols = symbols[batch_start:batch_start + batch_size]
            self.logger.info(
                f"ğŸ” åˆ†ææ‰¹æ¬¡ {batch_start // batch_size + 1}/{(len(symbols) - 1) // batch_size + 1}: {len(batch_symbols)} åª")

            with ThreadPoolExecutor(max_workers=workers) as executor:
                future_to_symbol = {executor.submit(task, sym): sym for sym in batch_symbols}

                for future in as_completed(future_to_symbol):
                    sym = future_to_symbol[future]
                    try:
                        symbol, payload = future.result()
                        if payload:
                            results[symbol] = payload
                    except Exception as e:
                        self.logger.debug(f"å¹¶å‘ä»»åŠ¡å¼‚å¸¸ {sym}: {e}")

            # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
            import time
            time.sleep(0.3)  # ä¼˜åŒ–ï¼šä»0.5å‡å°‘åˆ°0.3ï¼ŒåŠ å¿«é€Ÿåº¦

        return results

    def _safe_get_history_kline(self, symbol: str, bars: int) -> Optional[pd.DataFrame]:
        """
        å®‰å…¨è·å–å†å²Kçº¿ï¼ˆå°è¯• broker.get_history_klineï¼‰ï¼Œå¤±è´¥åˆ™è¿”å› Noneï¼ˆä¸Šå±‚å†³å®šæ˜¯å¦ mockï¼‰
        å·²ä¼˜åŒ–ï¼šæ·»åŠ ç¼“å­˜æ”¯æŒ
        """
        # æ£€æŸ¥ç¼“å­˜
        if self.data_cache:
            cached_kline = self.data_cache.get(symbol, 'kline', bars=bars)
            if cached_kline is not None:
                return cached_kline
        
        if not self.broker or not hasattr(self.broker, 'get_history_kline'):
            if self.parameters.get('allow_mock_market_data'):
                return self._generate_mock_kline(symbol, bars=bars)
            return None

        try:
            kline = self.broker.get_history_kline(symbol, ktype="K_DAY", max_count=bars)
            if kline is not None and not kline.empty:
                # å­˜å…¥ç¼“å­˜
                if self.data_cache:
                    self.data_cache.set(symbol, 'kline', kline, bars=bars)
                return kline
            return None
        except Exception as e:
            self.logger.debug(f"get_history_kline å¼‚å¸¸ {symbol}: {e}")
            return None

    # ---------- æ¿å—åˆ†æ•£è§„åˆ™ ----------
    def _select_diversified(self, ranked: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°½é‡ä¿è¯æ¿å—åˆ†æ•£ï¼Œå°½é‡æ¨¡ä»¿æ—§è„šæœ¬ï¼ˆç¬¬ä¸€è½®ï¼šæ¯æ¿å—å–ç¬¬ä¸€åï¼›ç¬¬äºŒè½®æŒ‰åˆ†è¡¥å……ï¼‰
        """
        max_stocks = int(self.parameters.get('max_stocks', 20))
        per_sector_max = max(1, int(max_stocks / 4))
        if not ranked:
            return []

        sector_buckets: Dict[str, List[Dict[str, Any]]] = {}
        for item in ranked:
            sec = self._get_stock_sector(item['symbol'])
            sector_buckets.setdefault(sec, []).append(item)

        selected = []
        sector_counts = {}

        # ç¬¬ä¸€è½®ï¼šæ¯ä¸ªæ¿å—å–ç¬¬ä¸€å
        for sec, arr in sector_buckets.items():
            if arr:
                selected.append(arr[0])
                sector_counts[sec] = 1

        # ç¬¬äºŒè½®ï¼šæŒ‰å¾—åˆ†è¡¥å……ï¼Œå°Šé‡æ¯æ¿å—ä¸Šé™
        for item in ranked:
            if len(selected) >= max_stocks:
                break
            if item in selected:
                continue
            sec = self._get_stock_sector(item['symbol'])
            cnt = sector_counts.get(sec, 0)
            if cnt < per_sector_max:
                selected.append(item)
                sector_counts[sec] = cnt + 1

        # æŒ‰å¾—åˆ†æ’åºåè¿”å›
        return sorted(selected, key=lambda x: x['score'], reverse=True)[:max_stocks]

    # ---------- åˆå¹¶ä¼˜å…ˆé€»è¾‘ ----------
    def _merge_priority_and_trim(self, final_list: List[Dict[str, Any]], priority_list: List[str]) -> List[
        Dict[str, Any]]:
        """
        ç¡®ä¿ priority_listï¼ˆè‡ªé€‰ï¼‰èƒ½è¿›å…¥ç»“æœï¼Œä¸”å…è®¸ priority_boost æŠŠåˆ†æ•°æå‡ï¼ˆå¯è¶… 100ï¼‰
        """
        if not priority_list:
            return final_list[:self.parameters.get('max_stocks', 20)]

        max_stocks = int(self.parameters.get('max_stocks', 20))
        quota = int(self.parameters.get('priority_quota', 5))
        boost = float(self.parameters.get('priority_boost', 10.0))
        allow_mock = bool(self.parameters.get('allow_mock_market_data', False))

        # ç°æœ‰ symbol é›†åˆ
        exist = {it['symbol'] for it in final_list}
        inserted = 0
        # ä¼˜å…ˆä¿ç•™å·²ç»åœ¨ final çš„ priority
        retained = [it for it in final_list if it['symbol'] in priority_list]

        # å¯¹æ²¡æœ‰è¿›å…¥ final çš„ priority åšè¡¥æ•‘
        need = [p for p in priority_list if p not in exist]
        for p in need:
            if inserted >= quota:
                break
            snap = self._safe_get_market_snapshot([p]).get(p, {}) if self.broker else {}
            if not snap and not allow_mock:
                continue
            kline = self._safe_get_history_kline(p, int(self.parameters.get('history_min_bars', DEFAULT_HISTORY_BARS)))
            if kline is None and not allow_mock:
                continue
            kline = kline if kline is not None else self._generate_mock_kline(p, bars=int(
                self.parameters.get('history_min_bars', DEFAULT_HISTORY_BARS)))
            indicators = {}
            try:
                ta = self.technical_analyzer.analyze_conditions(kline)
                multi = self.scorer.calculate_comprehensive_score(p, kline, snap)
                base = float(ta.get('total_score', 0) or 0)
                mscore = float(multi.get('final_score', 0) or 0)
                base_composite = self.parameters['w_tech'] * base + self.parameters['w_multi'] * mscore
                boosted = base_composite + boost
                # ä¸ºä¼˜å…ˆè‚¡ç”Ÿæˆç†ç”±
                reason = f"è‡ªé€‰ä¼˜å…ˆè‚¡ | {self._get_score_reason(boosted)}"
            except Exception:
                boosted = boost  # æœ€ä½ä¹Ÿç»™ä¸€ä¸ª boost
                reason = "è‡ªé€‰ä¼˜å…ˆè‚¡"

            cand = {
                'symbol': p,
                'score': float(boosted),
                'indicators': indicators,
                'snapshot': snap,
                'reason': reason
            }
            final_list.append(cand)
            inserted += 1
            self.logger.info(f"   âœ… è‡ªé€‰è‚¡å…¥é€‰: {p}ï¼Œæåˆ†åå¾—åˆ†: {boosted:.1f}ï¼Œç†ç”±: {reason}")

        # å»é‡ï¼šä¿ç•™æœ€é«˜åˆ†
        uniq = {}
        for it in final_list:
            sym = it.get('symbol')
            if not sym:
                continue
            if sym not in uniq or it.get('score', 0) > uniq[sym].get('score', 0):
                uniq[sym] = it

        merged = sorted(list(uniq.values()), key=lambda x: x.get('score', 0), reverse=True)[:max_stocks]
        return merged

    # ---------- è¾…åŠ©å·¥å…· ----------
    def _get_stock_sector(self, symbol: str) -> str:
        try:
            code = symbol.replace('HK.', '')
            return self.sector_map.get(code, 'å…¶ä»–')
        except Exception:
            return 'å…¶ä»–'

    def _generate_mock_market_data(self, universe: List[str]) -> Dict[str, Any]:
        res = {}
        for s in universe:
            p = round(random.uniform(5, 200), 2)
            res[s] = {
                'last_price': p,
                'volume': random.randint(100_000, 50_000_000),
                'market_cap': random.uniform(1e8, 1e11),
                'total_market_val': random.uniform(1e8, 1e11),
                'change_rate': random.uniform(-0.05, 0.05),
                'name': s
            }
        return res

    def _generate_mock_kline(self, symbol: str, bars: int = DEFAULT_HISTORY_BARS) -> pd.DataFrame:
        import numpy as _np
        dates = pd.date_range(end=pd.Timestamp.today(), periods=bars)
        price = _np.cumsum(_np.random.randn(bars)) + 50.0
        df = pd.DataFrame({
            'time_key': dates,
            'open': price,
            'close': price + _np.random.randn(bars),
            'high': price + abs(_np.random.randn(bars)),
            'low': price - abs(_np.random.randn(bars)),
            'volume': (_np.random.rand(bars) * 1e6).astype(int)
        })
        return df

    def _ensure_debug_logging(self):
        """
        å¦‚æœæ—¥å¿—çº§åˆ«æœªè¢«å¤–éƒ¨è®¾ç½®ä¸º DEBUGï¼Œåˆ™ä¸´æ—¶å°†å½“å‰ logger è®¾ä¸º DEBUGï¼Œä¾¿äºå¯¹é½æ—§è„šæœ¬è¾“å‡º
        ï¼ˆæ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒä¸ä¸€å®šè¦æŒç»­ DEBUGï¼‰
        """
        try:
            # å¦‚æœæ ¹ logger æˆ–å½“å‰ logger ç­‰çº§ä¸æ˜¯ DEBUGï¼Œåˆ™ä¸´æ—¶è®¾ç½® DEBUG
            if logging.getLogger().level != logging.DEBUG:
                logging.getLogger().setLevel(logging.DEBUG)
            self.logger.setLevel(logging.DEBUG)
        except Exception:
            pass

    def get_performance_metrics(self) -> Dict[str, Any]:
        base = super().get_performance_metrics()
        base.update({
            'parameters': self.parameters,
            'performance_stats': self.performance_stats
        })
        return base


# å¯¼å‡º
__all__ = ['TechnicalSelectionStrategy']

